version: '3'
services:
  database:
    image: postgres:13.2-alpine
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DATABASE=postgres
    networks:
      - spark
    ports:
      - 5432:5432

  odd-platform:
    image: ghcr.io/opendatadiscovery/odd-platform:latest
    restart: always
    environment:
      - SPRING_DATASOURCE_URL=jdbc:postgresql://database:5432/postgres
      - SPRING_DATASOURCE_USERNAME=postgres
      - SPRING_DATASOURCE_PASSWORD=postgres
    depends_on:
      - database
    ports:
      - 8082:8080
    networks:
      - spark

  spark:
    image: bitnami/spark:3.3.2
    environment:
      - SPARK_MODE=master
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      - ./data:/data
      - ./src:/src
    networks:
      - spark

  spark-worker:
    image: bitnami/spark:3.3.2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_EXECUTOR_MEMORY=4G
      - SPARK_WORKER_CORES=4
    networks:
      - spark
    ports:
      - '8081:8081'
    volumes:
      - ./data:/data
      - ./src:/src

  minio:
    image: minio/minio
    ports:
      - '9000:9000'
      - "9001:9001"
    environment:
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
    networks:
      - spark
    volumes:
      - ./minio:/data
    entrypoint: sh
    command: -c 'mkdir -p /data/deltalake && minio server --console-address ":9001" /data'

  jupyter:
    image: jupyter/pyspark-notebook:spark-3.3.2
    ports:
      - '8890:8888'
    volumes:
      - ./jars:/jars
      - ./data:/data
      - ./notebooks/delta_lake.ipynb:/home/jovyan/delta_lake.ipynb
    command: "start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''"
    networks:
      - spark

  odd-collector-aws:
    image: ghcr.io/opendatadiscovery/odd-collector-aws:latest
    environment:
      - PLATFORM_HOST_URL=http://odd-platform:8080
      - DEFAULT_PULLING_INTERVAL=60
    networks:
      - spark
    volumes:
      - ./config/collector_config.yaml:/app/collector_config.yaml
networks:
  spark:
    external: true
    name: spark
